model_name: "basic_char_emformer"

num_text_tokens: 1023
num_total_symbols: 1024
blank_idx: 1023

tokenizer:
  _target_: sentencepiece.SentencePieceProcessor
  model_file: /home/jake/rnnt/spm_unigram_1023.model

featurizer:
  _target_: rnnt.featurizer.NormalizedMelSpectrogram
  sample_rate: 16000
  n_fft: 512
  win_length: 400
  hop_length: 160
  n_mels: 80
  f_min: 0
  f_max: 8000
  apply_linear_log: True
  mean: 15.0
  invstddev: 0.25

predictor:
 _target_: rnnt.predictor.ConvPredictor
 num_symbols: ${num_total_symbols} 
 output_dim: 1024
 symbol_embedding_dim: 512
 dropout: 0.3

encoder:
  _target_: rnnt.emformer.EmformerEncoder
  input_dim: ${featurizer.n_mels}
  output_dim: 1024
  segment_length: 16
  right_context_length: 4
  time_reduction_input_dim: 128
  time_reduction_stride: 4
  transformer_num_heads: 8
  transformer_ffn_dim: 2048
  transformer_num_layers: 20
  transformer_dropout: 0.1
  transformer_activation: gelu
  transformer_left_context_length: 30
  transformer_max_memory_size: 0
  transformer_weight_init_scale_strategy: depthwise
  transformer_tanh_on_mem: True

joint:
  _target_: rnnt.joint.JointNetwork
  audio_features: ${encoder.output_dim}
  text_features: 1024
  hidden_features: 1024
  num_classes: ${num_total_symbols}



training:
  mixed_precision: fp32
  num_epochs: 1
  log_steps: 2000
  eval_steps: 20000
  checkpoint_steps: 100000
  max_joint_size: 160000


  pergpu_minibatch_size: 4
  #perstep_batch_size: 256

  clip_grad_norm: 10.0
  rnnt_grad_clamp: -1

  optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    eps: 1e-8
    betas: [0.9, 0.999]
    weight_decay: 0.01
  
  lr_scheduler:
    _target_: rnnt.lr_sched.WarmupCosineDecayLR
    warmup_steps: 2000
    min_lr_ratio: 0.05
    total_steps: ???


datasets:
  cache_dir: /media/datasets/librispeech_hf

  librispeech_100:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.100"
    cache_dir: ${datasets.cache_dir}
  librispeech_360:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.360"
    cache_dir: ${datasets.cache_dir}
  librispeech_500:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.other.500"
    cache_dir: ${datasets.cache_dir}
  librispeech_validation:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "validation.clean"
    cache_dir: ${datasets.cache_dir}

data:
  processor_class: rnnt.dataset.AudioDatasetProcessor

  train:
    dataset:
        - ${datasets.librispeech_100}
        - ${datasets.librispeech_360}
        - ${datasets.librispeech_500}

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: ${training.pergpu_minibatch_size}
      shuffle: True
      num_workers: 4
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator

  eval:
    dataset: ${datasets.librispeech_validation}
    max_elements: 1000

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: 1
      shuffle: False
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator




