model_name: "basic_char_convjs"

num_text_tokens: 1023
num_total_symbols: 1024
blank_idx: 1023

tokenizer:
  _target_: sentencepiece.SentencePieceProcessor
  model_file: /home/jake/rnnt/spm_unigram_1023.model

featurizer:
  _target_: rnnt.featurizer.TFJSSpectrogram
  n_fft: 400
  win_length: 400
  hop_length: 160
  apply_linear_log: True
  mean: [15.72, 16.66, 17.06, 17.62, 18.09, 18.24, 17.96, 17.55, 17.35, 17.32, 17.28, 17.17, 17.00, 16.80, 16.54, 16.23, 15.92, 15.63, 15.40, 15.22, 15.07, 14.93, 14.80, 14.68, 14.57, 14.48, 14.38, 14.30, 14.23, 14.17, 14.11, 14.08, 14.06, 14.05, 14.13, 14.13, 14.09, 14.12, 14.13, 14.13, 14.12, 14.10, 14.08, 14.05, 14.02, 13.97, 13.93, 13.89, 13.84, 13.80, 13.77, 13.71, 13.66, 13.63, 13.61, 13.59, 13.58, 13.57, 13.56, 13.55, 13.55, 13.55, 13.54, 13.54, 13.52, 13.50, 13.47, 13.44, 13.40, 13.37, 13.34, 13.31, 13.28, 13.26, 13.24, 13.24, 13.20, 13.16, 13.13, 13.09, 13.05, 13.02, 12.99, 12.96, 12.93, 12.90, 12.87, 12.84, 12.81, 12.78, 12.75, 12.72, 12.69, 12.67, 12.64, 12.62, 12.59, 12.57, 12.54, 12.52, 12.50, 12.44, 12.39, 12.37, 12.32, 12.27, 12.23, 12.19, 12.15, 12.11, 12.07, 12.03, 11.99, 11.95, 11.91, 11.87, 11.83, 11.79, 11.76, 11.72, 11.68, 11.64, 11.60, 11.56, 11.54, 11.52, 11.46, 11.42, 11.39, 11.36, 11.33, 11.30, 11.28, 11.25, 11.23, 11.20, 11.18, 11.16, 11.14, 11.11, 11.09, 11.07, 11.05, 11.03, 11.01, 10.99, 10.97, 10.96, 10.94, 10.95, 10.96, 10.93, 10.90, 10.89, 10.89, 10.88, 10.87, 10.86, 10.85, 10.84, 10.83, 10.82, 10.81, 10.79, 10.77, 10.75, 10.74, 10.72, 10.70, 10.69, 10.67, 10.66, 10.65, 10.63, 10.62, 10.63, 10.59, 10.56, 10.54, 10.53, 10.51, 10.49, 10.48, 10.46, 10.45, 10.43, 10.42, 10.41, 10.39, 10.38, 10.36, 10.34, 10.33, 10.31, 10.30, 10.28, 10.25, 10.23, 10.20, 10.19, 9.87]
  invstddev: [0.24, 0.28, 0.26, 0.23, 0.22, 0.21, 0.21, 0.22, 0.22, 0.21, 0.21, 0.21, 0.21, 0.22, 0.22, 0.22, 0.23, 0.23, 0.23, 0.24, 0.24, 0.25, 0.25, 0.25, 0.25, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.27, 0.27, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.27, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.28, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.29, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.30, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.31, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.32, 0.33, 0.33, 0.33]

predictor:
 _target_: rnnt.predictor.ConvPredictor
 num_symbols: ${num_total_symbols} 
 output_dim: 1024
 symbol_embedding_dim: 512
 dropout: 0.3

encoder:
  _target_: rnnt.jasper.AudioEncoder
  input_features: 201
  norm_type: instance_affine
  prologue_kernel_size: 11
  prologue_stride: 2
  blocks:
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 11
      in_channels: 256
      out_channels: 256
      dropout: 0.2
      num_sub_blocks: 4
      norm_type: instance_affine
      additional_context: 2
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 13
      in_channels: 256
      out_channels: 384
      dropout: 0.2
      num_sub_blocks: 4   
      norm_type: instance_affine   
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 25
      in_channels: 384
      out_channels: 512
      dropout: 0.3
      num_sub_blocks: 4                
      norm_type: instance_affine
  epilogue_features: 512
  epilogue_kernel_size: 29
  epilogue_dilation: 2
  output_features: 1024

joint:
  _target_: rnnt.joint.JointNetwork
  # -1 disables the extra Linear layer for those features
  audio_features: -1 
  text_features: -1
  hidden_features: 1024
  num_classes: ${num_total_symbols}



training:
  mixed_precision: fp32
  num_epochs: 1
  log_steps: 2000
  eval_steps: 20000
  checkpoint_steps: 100000
  max_joint_size: 160000


  pergpu_minibatch_size: 4
  #perstep_batch_size: 256

  clip_grad_norm: 10.0
  rnnt_grad_clamp: -1

  optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    eps: 1e-8
    betas: [0.95, 0.9999]
    weight_decay: 0.01
  
  lr_scheduler:
    _target_: rnnt.lr_sched.WarmupCosineDecayLR
    warmup_steps: 2000
    min_lr_ratio: 0.05
    total_steps: ???


datasets:
  cache_dir: /media/datasets/librispeech_hf

  librispeech_100:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.100"
    cache_dir: ${datasets.cache_dir}
  librispeech_360:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.360"
    cache_dir: ${datasets.cache_dir}
  librispeech_500:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.other.500"
    cache_dir: ${datasets.cache_dir}
  librispeech_validation:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "validation.clean"
    cache_dir: ${datasets.cache_dir}

data:
  processor_class: rnnt.dataset.AudioDatasetProcessor

  train:
    dataset:
        - ${datasets.librispeech_100}
        - ${datasets.librispeech_360}
        - ${datasets.librispeech_500}

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: ${training.pergpu_minibatch_size}
      shuffle: True
      num_workers: 4
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator

  eval:
    dataset: ${datasets.librispeech_validation}
    max_elements: 1000

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: 1
      shuffle: False
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator




