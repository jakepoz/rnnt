model_name: "basic_char_convjs"

num_text_tokens: 1023
num_total_symbols: 1024
blank_idx: 1023

tokenizer:
  _target_: sentencepiece.SentencePieceProcessor
  model_file: /home/jake/rnnt/spm_unigram_1023.model

featurizer:
  _target_: rnnt.featurizer.TFJSSpectrogram
  n_fft: 400
  win_length: 400
  hop_length: 160
  apply_linear_log: True
  mean: 15.0
  invstddev: 0.25

predictor:
 _target_: rnnt.predictor.ConvPredictor
 num_symbols: ${num_total_symbols} 
 output_dim: 1024
 symbol_embedding_dim: 512
 dropout: 0.3

encoder:
  _target_: rnnt.jasper.AudioEncoder
  input_features: 201
  norm_type: instance_affine
  prologue_kernel_size: 11
  prologue_stride: 2
  blocks:
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 11
      in_channels: 256
      out_channels: 256
      dropout: 0.2
      num_sub_blocks: 4
      norm_type: instance_affine
      additional_context: 2
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 13
      in_channels: 256
      out_channels: 384
      dropout: 0.2
      num_sub_blocks: 4   
      norm_type: instance_affine   
    - _target_: rnnt.jasper.JasperBlock
      kernel_size: 25
      in_channels: 384
      out_channels: 512
      dropout: 0.3
      num_sub_blocks: 4                
      norm_type: instance_affine
  epilogue_features: 512
  epilogue_kernel_size: 29
  epilogue_dilation: 2
  output_features: 1024

joint:
  _target_: rnnt.joint.JointNetwork
  # -1 disables the extra Linear layer for those features
  audio_features: -1 
  text_features: -1
  hidden_features: 1024
  num_classes: ${num_total_symbols}



training:
  mixed_precision: fp32
  num_epochs: 1
  log_steps: 2000
  eval_steps: 20000
  checkpoint_steps: 100000
  max_joint_size: 160000


  pergpu_minibatch_size: 4
  #perstep_batch_size: 256

  clip_grad_norm: 10.0
  rnnt_grad_clamp: -1

  optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    eps: 1e-8
    betas: [0.95, 0.9999]
    weight_decay: 0.01
  
  lr_scheduler:
    _target_: rnnt.lr_sched.WarmupCosineDecayLR
    warmup_steps: 2000
    min_lr_ratio: 0.05
    total_steps: ???


datasets:
  cache_dir: /media/datasets/librispeech_hf

  librispeech_100:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.100"
    cache_dir: ${datasets.cache_dir}
  librispeech_360:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.clean.360"
    cache_dir: ${datasets.cache_dir}
  librispeech_500:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "train.other.500"
    cache_dir: ${datasets.cache_dir}
  librispeech_validation:
    _target_: rnnt.dataset.get_librispeech_dataset
    split: "validation.clean"
    cache_dir: ${datasets.cache_dir}

data:
  processor_class: rnnt.dataset.AudioDatasetProcessor

  audio_augmentation:
    _target_: rnnt.augment.TimeDomainAugmentor
    augmentations:
      - _target_: rnnt.augment.ATempoAugmentation
        p: 0.5
        min_tempo_rate: 0.75
        max_tempo_rate: 1.25
      - _target_: rnnt.augment.PitchShiftAugmentation
        p: 0.5
        min_semitones: -3
        max_semitones: 3
      - _target_: rnnt.augment.TrimAugmentation
        p: 0.5
        max_trim: 0.02
        
  train:
    dataset:
        - ${datasets.librispeech_100}
        - ${datasets.librispeech_360}
        - ${datasets.librispeech_500}

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: ${training.pergpu_minibatch_size}
      shuffle: True
      num_workers: 4
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator

  eval:
    dataset: ${datasets.librispeech_validation}
    max_elements: 1000

    dataloader:
      _target_: torch.utils.data.DataLoader
      batch_size: 1
      shuffle: False
      collate_fn:
        _target_: rnnt.dataset.AudioDatasetCollator




